# E-NSGA-II + X-MARL: Explainable Multi-Objective Reinforcement Learning for Portfolio Optimization

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

Official implementation of **"E-NSGA-II + X-MARL: A Lightweight Explainable Multi-Objective Reinforcement Framework for Financial Portfolio Optimization"**

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Usage](#usage)
- [Experiments](#experiments)
- [Results](#results)
- [Citation](#citation)
- [License](#license)

## ğŸ” Overview

This repository implements a novel hybrid framework combining:
- **Enhanced NSGA-II** with Explainability Dominance operator
- **Explainable Multi-Agent RL** with three specialized agents
- **SHAP-based explainability** for interpretable trading decisions
- **CVaR risk management** for robust portfolio construction

### Key Innovations

1. **Explainability Dominance Operator**: Extends NSGA-II to prefer interpretable solutions
2. **Multi-Objective Optimization**: Jointly optimizes return, risk (CVaR), and explainability
3. **Lightweight Design**: Runs on standard CPU hardware (3 hours on laptop)
4. **Full Reproducibility**: Open data, code, and trained models

## âœ¨ Features

- âœ… **Complete Implementation** of paper methodology
- âœ… **8 Baseline Methods** for comprehensive comparison:
  - Traditional: Equal-weight, Minimum-variance, Risk-parity
  - Deep Learning: LSTM, DDPG, Single-agent PPO
  - Evolutionary: Pure NSGA-II
  - Proposed: E-NSGA-II + X-MARL
- âœ… **Ablation Studies** (Î´=0, single-agent variants)
- âœ… **SHAP Explainability** with temporal stability analysis
- âœ… **CVaR Risk Metrics** for tail risk management
- âœ… **Hypervolume Indicator** for Pareto front quality
- âœ… **Automated Experiment Pipeline** with result aggregation

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10 or higher
- pip package manager
- 8GB+ RAM recommended

### Setup

```bash
# Clone repository
git clone https://github.com/yourusername/MARL_NSGA_II.git
cd MARL_NSGA_II

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Dependencies

Core libraries:
- `numpy`, `pandas`, `scipy` - Data processing
- `torch` - Deep learning
- `gymnasium` - RL environment
- `shap` - Explainability
- `yfinance` - Financial data
- `matplotlib`, `seaborn` - Visualization
- `deap` - Evolutionary algorithms

See [requirements.txt](requirements.txt) for full list.

## ğŸš€ Quick Start

### 1. Run Quick Tests

Verify installation and test all components:

```bash
./quick_test.sh
```

This runs:
- Module import tests
- Data file checks
- Environment creation
- Metrics calculation
- Quick baseline test

### 2. Download and Prepare Data

```bash
# Download S&P 500 data (2020-2025)
python data/downloader.py

# Preprocess and split data
python data/preprocessor.py
```

This creates:
- `data/train.csv` (2020-2023, ~1,007 days)
- `data/val.csv` (2024, ~252 days)
- `data/test.csv` (2025, ~230 days)

### 3. Run Complete Experiments

#### Quick Mode (for testing)
```bash
./run_all_experiments.sh --quick
```
- Reduced parameters (pop=5, gen=3, epochs=5)
- Single random seed
- ~30 minutes runtime

#### Full Experiments
```bash
./run_all_experiments.sh
```
- Full parameters (pop=20, gen=10)
- 3 random seeds for statistical validation
- ~6-8 hours runtime

#### Baselines Only
```bash
./run_all_experiments.sh --baselines-only
```
- Skips ablations and main method
- ~3-4 hours runtime

## ğŸ“ Project Structure

```
MARL_NSGA_II/
â”œâ”€â”€ data/                          # Data handling
â”‚   â”œâ”€â”€ downloader.py             # S&P 500 data download
â”‚   â”œâ”€â”€ preprocessor.py           # Feature engineering & splits
â”‚   â”œâ”€â”€ train.csv                 # Training data (generated)
â”‚   â”œâ”€â”€ val.csv                   # Validation data (generated)
â”‚   â””â”€â”€ test.csv                  # Test data (generated)
â”‚
â”œâ”€â”€ env/                          # RL Environment
â”‚   â””â”€â”€ portfolio_env.py          # Portfolio optimization environment
â”‚
â”œâ”€â”€ models/                       # Agent models
â”‚   â””â”€â”€ agents.py                 # ReturnAgent, RiskAgent, ExplainAgent
â”‚
â”œâ”€â”€ algorithms/                   # Optimization algorithms
â”‚   â””â”€â”€ nsga_ii.py                # Enhanced NSGA-II with E-Dominance
â”‚
â”œâ”€â”€ baselines/                    # Baseline implementations
â”‚   â”œâ”€â”€ traditional.py            # Equal-weight, Min-variance, Risk-parity
â”‚   â”œâ”€â”€ pure_nsga_ii.py          # Pure NSGA-II (no RL)
â”‚   â”œâ”€â”€ lstm_baseline.py         # LSTM predictor
â”‚   â”œâ”€â”€ ddpg_baseline.py         # DDPG agent
â”‚   â”œâ”€â”€ single_ppo.py            # Single-agent PPO
â”‚   â””â”€â”€ ablations.py             # Ablation study variants
â”‚
â”œâ”€â”€ utils/                        # Utility modules
â”‚   â”œâ”€â”€ metrics.py                # Performance metrics, hypervolume
â”‚   â”œâ”€â”€ risk_metrics.py           # CVaR, VaR, Sortino, etc.
â”‚   â””â”€â”€ explainability.py         # SHAP-based explainability scorer
â”‚
â”œâ”€â”€ results/                      # Experiment results (generated)
â”‚   â”œâ”€â”€ baselines/               # Baseline results
â”‚   â”œâ”€â”€ ablations/               # Ablation study results
â”‚   â”œâ”€â”€ main_method/             # E-NSGA-II + X-MARL results
â”‚   â”œâ”€â”€ figures/                 # Visualizations
â”‚   â””â”€â”€ RESULTS_SUMMARY.csv      # Aggregated comparison table
â”‚
â”œâ”€â”€ logs/                         # Execution logs (generated)
â”‚
â”œâ”€â”€ main.py                       # Main training script
â”œâ”€â”€ run_all_experiments.sh        # Complete experiment pipeline
â”œâ”€â”€ quick_test.sh                 # Quick validation tests
â”œâ”€â”€ requirements.txt              # Python dependencies
â”‚
â””â”€â”€ docs/                         # Documentation
    â”œâ”€â”€ IMPLEMENTATION_REVIEW.md  # Gap analysis vs paper
    â”œâ”€â”€ IMPROVEMENT_CHECKLIST.md  # Action items
    â”œâ”€â”€ CRITICAL_GAPS_SUMMARY.md  # Quick reference
    â””â”€â”€ PHASE_1_2_3_IMPLEMENTATION_SUMMARY.md
```

## ğŸ’» Usage

### Running Individual Components

#### Traditional Baselines
```python
from baselines.traditional import TraditionalBaselines
from env.portfolio_env import PortfolioEnv
import pandas as pd

test_df = pd.read_csv('data/test.csv', index_col=[0, 1], parse_dates=True)
env = PortfolioEnv(test_df)
bl = TraditionalBaselines(env)

# Equal-weight strategy
weights = bl.equal_weight()

# Minimum-variance portfolio
weights = bl.min_variance(lookback=60)

# Risk-parity allocation
weights = bl.risk_parity(lookback=60)
```

#### LSTM Baseline
```python
from baselines.lstm_baseline import LSTMBaseline, run_lstm_baseline

# Create and train LSTM
lstm = LSTMBaseline(n_assets=10, n_features=11, lookback=20)
lstm.train(env_train, epochs=10)

# Get portfolio weights
action = lstm.get_action(state)

# Or run complete pipeline
results = run_lstm_baseline(env_train, env_val, env_test, epochs=10)
```

#### DDPG Baseline
```python
from baselines.ddpg_baseline import DDPGAgent, run_ddpg_baseline

# Create DDPG agent
agent = DDPGAgent(state_dim=110, action_dim=11)

# Train
for episode in range(100):
    # ... training loop
    agent.train(batch_size=64)

# Or run complete pipeline
results = run_ddpg_baseline(env_train, env_val, env_test, episodes=100)
```

#### Single-Agent PPO
```python
from baselines.single_ppo import PPOAgent, run_single_ppo_baseline

# Create PPO agent with scalarized reward
agent = PPOAgent(
    state_dim=110,
    action_dim=11,
    reward_weights=(0.5, 0.3, 0.2)  # (sharpe, risk, explain)
)

# Or run complete pipeline
results = run_single_ppo_baseline(
    env_train, env_val, env_test,
    episodes=100,
    reward_weights=(0.5, 0.3, 0.2)
)
```

#### Pure NSGA-II
```python
from baselines.pure_nsga_ii import PureNSGAII, run_pure_nsga_ii_baseline

# Direct weight optimization (no RL)
optimizer = PureNSGAII(n_assets=11, population_size=20, generations=10)
final_pop, final_fitness = optimizer.evolve(evaluate_fn)

# Or run complete pipeline
results = run_pure_nsga_ii_baseline(
    env_train, env_val, env_test,
    population_size=20,
    generations=10
)
```

#### Main Method (E-NSGA-II + X-MARL)
```bash
python main.py --pop_size 20 --generations 10
```

Or with custom parameters:
```bash
python main.py --pop_size 50 --generations 40 --test
```

### Calculating Metrics

```python
from utils.metrics import calculate_metrics, calculate_hypervolume
from utils.risk_metrics import calculate_cvar, calculate_sortino_ratio
from utils.explainability import ExplainabilityScorer

# Portfolio performance metrics
metrics = calculate_metrics(portfolio_history, risk_free_rate=0.04)
print(f"Sharpe Ratio: {metrics['Sharpe Ratio']:.4f}")
print(f"CVaR 95%: {metrics['CVaR 95%']:.4f}")

# Hypervolume for Pareto front quality
hv = calculate_hypervolume(pareto_front, reference_point=None)

# SHAP-based explainability
scorer = ExplainabilityScorer(n_rollouts=50, method='deep')
E = scorer.calculate_explainability_score(agent, env, obs_dim, action_dim)
```

## ğŸ§ª Experiments

### Experimental Setup

As per paper specifications:

| Parameter | Value |
|-----------|-------|
| Population size | 20 |
| Generations | 10 |
| Episodes per evaluation | 150 (50 timesteps) |
| Learning rate | 3 Ã— 10â»â´ |
| Discount factor (Î³) | 0.95 |
| Mutation rate | 0.1 |
| Crossover rate | 0.8 |
| Transaction cost | 5 bps (0.05%) |

### Data Splits

| Period | Dates | Trading Days | Usage |
|--------|-------|--------------|-------|
| Training | 2020-01-01 â†’ 2023-12-31 | ~1,007 | NSGA-II evolution |
| Validation | 2024-01-01 â†’ 2024-12-31 | ~252 | Model selection |
| Test | 2025-01-01 â†’ 2025-11-30 | ~230 | Final evaluation |

### Features (per stock)

- Past returns: 1, 5, 10, 20, 60 days
- Normalized rank of returns
- Volume ratio (vs 20-day average)
- Rolling Sharpe (20-day)
- Rolling volatility (20-day)
- Distance from 52-week high/low
- **Total: 11 features Ã— n assets**

### Evaluation Metrics

1. Annualized Return (AR)
2. Annualized Volatility (Ïƒ)
3. Sharpe Ratio (SR)
4. Maximum Drawdown
5. Calmar Ratio
6. Annual Turnover
7. Average Transaction Cost
8. CVaR-95%
9. Sortino Ratio
10. Explainability Score (E)
11. Hypervolume (Pareto quality)

## ğŸ“Š Results

Results are automatically generated and saved to `results/RESULTS_SUMMARY.csv`.

### Expected Output Format

```csv
Method,Annualized Return,Annualized Volatility,Sharpe Ratio,CVaR 95%,Explainability
Equal-Weight,0.0980,0.1420,0.6900,0.0320,...
Min-Variance,0.0850,0.1180,0.7200,0.0280,...
LSTM,0.1120 Â± 0.0050,0.1350 Â± 0.0030,0.8300 Â± 0.0400,...
DDPG,0.1180 Â± 0.0060,0.1290 Â± 0.0040,0.9100 Â± 0.0500,...
Single-PPO,0.1240 Â± 0.0070,0.1260 Â± 0.0035,0.9800 Â± 0.0550,...
Pure NSGA-II,0.1310 Â± 0.0080,0.1230 Â± 0.0030,1.0600 Â± 0.0650,...
E-NSGA-II + X-MARL,0.1520 Â± 0.0090,0.1190 Â± 0.0025,1.2700 Â± 0.0750,...
```

### Visualization

Plots are saved to `results/figures/`:
- `sharpe_comparison.png` - Sharpe ratio across all methods
- `risk_return_tradeoff.png` - Return vs volatility scatter
- `pareto_front_3d.png` - 3D Pareto front (if generated)

## ğŸ“– Citation

If you use this code in your research, please cite:

```bibtex
@article{nguyen2025ensga,
  title={E-NSGA-II + X-MARL: A Lightweight Explainable Multi-Objective Reinforcement Framework for Financial Portfolio Optimization},
  author={Nguyen, Thanh},
  journal={[Journal Name]},
  year={2025}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“§ Contact

**Thanh Nguyen**
- Email: thanh.nguyen@fsb.edu.vn
- Institution: FSB School of Business and Technology

## ğŸ™ Acknowledgments

- S&P 500 data from Yahoo Finance via `yfinance`
- SHAP library by Lundberg & Lee
- DEAP evolutionary computation framework
- PyTorch deep learning framework

## ğŸ“ Version History

- **v1.0.0** (2025-11-19)
  - Initial release
  - All baseline implementations
  - SHAP explainability
  - CVaR risk metrics
  - Complete experiment pipeline

---

**Note:** This implementation has been extensively tested and validated against the paper requirements. See `IMPLEMENTATION_REVIEW.md` for detailed analysis.
